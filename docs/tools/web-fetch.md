# เครื่องมือดึงข้อมูลเว็บ (`web_fetch`)

เอกสารนี้อธิบายเครื่องมือ `web_fetch` สำหรับ Gemini CLI

## คำอธิบาย

ใช้ `web_fetch` เพื่อสรุป เปรียบเทียบ หรือดึงข้อมูลจากหน้าเว็บ เครื่องมือ `web_fetch` ประมวลผลเนื้อหาจาก URL หนึ่งหรือหลายตัว (สูงสุด 20) ที่ฝังอยู่ในพรอมต์ `web_fetch` รับพรอมต์ภาษาธรรมชาติและส่งคืนการตอบสนองที่สร้างขึ้น

### อาร์กิวเมนต์

`web_fetch` รับอาร์กิวเมนต์หนึ่งตัว:

- `prompt` (string, required): พรอมต์ที่ครอบคลุมซึ่งรวมถึง URL (สูงสุด 20) ที่จะดึงข้อมูลและคำแนะนำเฉพาะเกี่ยวกับวิธีการประมวลผลเนื้อหา ตัวอย่าง: `"สรุป https://example.com/article และดึงประเด็นสำคัญจาก https://another.com/data"` พรอมต์ต้องมี URL อย่างน้อยหนึ่งตัวที่เริ่มต้นด้วย `http://` หรือ `https://`

## วิธีใช้ `web_fetch` กับ Gemini CLI

เพื่อใช้ `web_fetch` กับ Gemini CLI ให้พรอมต์ภาษาธรรมชาติที่มี URLs เครื่องมือจะขอการยืนยันก่อนดึงข้อมูล URL ใดๆ เมื่อได้รับการยืนยันแล้ว เครื่องมือจะประมวลผล URLs ผ่าน `urlContext` ของ Gemini API

หาก Gemini API ไม่สามารถเข้าถึง URL ได้ เครื่องมือจะใช้วิธีสำรองโดยดึงเนื้อหาโดยตรงจากเครื่องในเครื่อง เครื่องมือจะจัดรูปแบบการตอบสนอง รวมถึงการระบุแหล่งที่มาและการอ้างอิงเมื่อเป็นไปได้ จากนั้นเครื่องมือจะให้การตอบสนองแก่ผู้ใช้

การใช้งาน:

```
web_fetch(prompt="พรอมต์ของคุณ รวมถึง URL เช่น https://google.com.")
```

## ตัวอย่าง `web_fetch`

สรุปบทความเดียว:

```
web_fetch(prompt="คุณช่วยสรุปประเด็นหลักของ https://example.com/news/latest ได้ไหม")
```

เปรียบเทียบสองบทความ:

```
web_fetch(prompt="ความแตกต่างในข้อสรุปของงานวิจัยสองชิ้นนี้คืออะไร: https://arxiv.org/abs/2401.0001 และ https://arxiv.org/abs/2401.0002?")
```

## หมายเหตุสำคัญ

- **การประมวลผล URL:** `web_fetch` อาศัยความสามารถของ Gemini API ในการเข้าถึงและประมวลผล URLs ที่กำหนด
- **คุณภาพของผลลัพธ์:** คุณภาพของผลลัพธ์จะขึ้นอยู่กับความชัดเจนของคำแนะนำในพรอมต์

## ข้อจำกัดและข้อควรพิจารณา

### ข้อจำกัด
- จำนวน URL สูงสุด: 20 URLs ต่อพรอมต์
- รองรับเฉพาะ URLs ที่เริ่มต้นด้วย `http://` หรือ `https://`
- ขึ้นอยู่กับการเข้าถึงของ Gemini API

### การจัดการข้อผิดพลาด
- หาก URL เข้าถึงไม่ได้ จะใช้วิธีสำรอง
- แจ้งเตือนเมื่อไม่สามารถดึงข้อมูลได้
- รายงานสถานะการเข้าถึงแต่ละ URL

## การเพิ่มประสิทธิภาพ

### เคล็ดลับการใช้งาน
- เขียนพรอมต์ที่ชัดเจนและเฉพาะเจาะจง
- ระบุงานที่ต้องการให้ทำกับเนื้อหา
- จัดกลุ่ม URLs ที่เกี่ยวข้องกัน

### การใช้งานขั้นสูง
- เปรียบเทียบข้อมูลจากหลายแหล่ง
- วิเคราะห์แนวโน้มจากหลายบทความ
- สร้างสรุปจากข้อมูลที่หลากหลาย
